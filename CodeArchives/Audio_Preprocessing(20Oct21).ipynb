{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "class AudioProcession():\n",
    "    # ----------------------------\n",
    "    # Load the full length audio files into python\n",
    "    # ----------------------------\n",
    "\n",
    "    @staticmethod\n",
    "    def open(fullPath):\n",
    "        signal, samplingRate = torchaudio.load(fullPath)\n",
    "        return (signal, samplingRate)\n",
    "    # ----------------------------\n",
    "    # Convert the full audio to stereo\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def rechannel(audio):\n",
    "        signal, samplingRate = audio\n",
    "\n",
    "        if (signal.shape[0] == 2):\n",
    "            # Nothing to do\n",
    "            return audio\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "            newSignal = torch.cat([signal, signal])\n",
    "\n",
    "        return ((newSignal, samplingRate))\n",
    "        # ----------------------------\n",
    "    # Resampling one channel at a time as we can only do so\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def resample(audio, newSamplingRate):\n",
    "        signal, samplingRate = audio\n",
    "\n",
    "        if (samplingRate == newSamplingRate):\n",
    "            # Nothing to do\n",
    "            return audio\n",
    "\n",
    "        # Resample first channel\n",
    "        channel1 = torchaudio.transforms.Resample(samplingRate, newSamplingRate)(signal[:1,:])\n",
    "        channel2 = torchaudio.transforms.Resample(samplingRate, newSamplingRate)(signal[1:,:])\n",
    "        newAudio = torch.cat([channel1, channel2])\n",
    "\n",
    "        return ((newAudio, newSamplingRate))\n",
    "    # ----------------------------\n",
    "    # Updates CSV file\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def updateCSV(classSerial, className, sampleName):\n",
    "        with open('metadata.csv', mode='a') as metadata:\n",
    "            csvWriter = csv.writer(metadata, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "            csvWriter.writerow([classSerial, className, sampleName])\n",
    "    # ----------------------------\n",
    "    # Saves file\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def saveAudio(audio, samplingRate, i, sampleName, className, classSerial):\n",
    "        currentPath = Path.cwd()\n",
    "        sampleName = sampleName.replace(\".wav\", \"\")\n",
    "        sampleName = sampleName + \"_\" + str(i) + \".wav\"\n",
    "        outputPath = str(currentPath) + \"/processedSamples/\" + className + \"/\" + sampleName\n",
    "        torchaudio.save(outputPath, audio, samplingRate, format=\"wav\")\n",
    "        AudioProcession.updateCSV(classSerial, className, sampleName)\n",
    "    # ----------------------------\n",
    "    # Resizing the full length audio files into the designated length of 4s\n",
    "    # Resize happens by moving window of length 4s by 2s each time until the end of audio file\n",
    "    # Remainder is padded with 0s at end of file\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def audioBreakdown(audio, sampleName, className, classSerial):\n",
    "        signal, samplingRate = audio\n",
    "        numRows, signalLength = signal.shape\n",
    "\n",
    "        #window length = 4s = 4000ms\n",
    "        #winLength of tensor = 4s * Samples/second\n",
    "        winLength = 4 * samplingRate\n",
    "        offset = 0\n",
    "        increment =  2 * samplingRate\n",
    "\n",
    "        #number of windows = length/2 - 1 (remainder half window) if multiple\n",
    "        isLengthMultiple = !int(signalLength % increment)\n",
    "        if (isLengthMultiple):\n",
    "            numWindows = int(signalLength / increment) - 1 \n",
    "        else:\n",
    "        #number of windows = length//2 - 1 (remainder half window) + 1 (remainder half window to end + padding)\n",
    "            numWindows = int(signalLength // increment)\n",
    "\n",
    "        if (isLengthMultiple):\n",
    "            for i in range(numWindows):\n",
    "                offset = i * increment\n",
    "                AudioProcession.saveAudio(signal[: , offset:offset+winLength], samplingRate, i, sampleName, className, classSerial)\n",
    "        else: \n",
    "            #for complete windows\n",
    "            for i in range(numWindows-1):\n",
    "                offset = i * increment\n",
    "                AudioProcession.saveAudio(signal[: , offset:offset+winLength], samplingRate, i, sampleName, className, classSerial)\n",
    "            #for last incomplete window\n",
    "            paddingLength = winLength - (signalLength - offset - increment)\n",
    "            #randomly distribute padding across start and end\n",
    "            paddingBefore = random.randint(0, paddingLength)\n",
    "            paddingAfter = paddingLength - paddingBefore\n",
    "            #create padding of zeros\n",
    "            paddingBefore = torch.zeros((numRows, paddingBefore))\n",
    "            paddingAfter = torch.zeros((numRows, paddingAfter))\n",
    "            #create and save last window\n",
    "            lastWindow = torch.cat((paddingBefore, signal[: , offset+winLength:], paddingAfter), 1)\n",
    "            AudioProcession.saveAudio(lastWindow, samplingRate, i+1, sampleName, className, classSerial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Process the audio files in a given foder (type)\n",
    "# ----------------------------\n",
    "def splitAudioInType(inputFolder, className, classSerial, samplingRate):\n",
    "    typeFolder = str(inputFolder) + \"/\" + className\n",
    "    fullLengthAudios = os.listdir(typeFolder)\n",
    "    for sampleName in fullLengthAudios:\n",
    "        fullPath = str(typeFolder) + \"/\" + sampleName\n",
    "        audio= AudioProcession.open(fullPath)\n",
    "        stereoed = AudioProcession.rechannel(audio)\n",
    "        resampled = AudioProcession.resample(stereoed, samplingRate)\n",
    "        AudioProcession.audioBreakdown(resampled, sampleName, className, classSerial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Moves the rawSamples into archivedSamples so that the next round of Processing will not generate duplicates\n",
    "# ----------------------------\n",
    "import shutil\n",
    "def archive():\n",
    "    inputFolder = str(Path.cwd()/'rawSamples')\n",
    "    outputFolder = str(Path.cwd()/'archivedSamples')\n",
    "    classes = os.listdir(inputFolder)\n",
    "    for currentClass in classes:\n",
    "        srcFolder = inputFolder + \"/\" + currentClass\n",
    "        destFolder = outputFolder + \"/\" + currentClass\n",
    "        files = os.listdir(srcFolder)\n",
    "        for file in files:\n",
    "            srcPath = srcFolder + \"/\" + file\n",
    "            destPath = destFolder + \"/\" + file\n",
    "            shutil.move(srcPath, destPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "samplingRate = 44100\n",
    "inputFolder = Path.cwd()/'rawSamples'\n",
    "classes = os.listdir(inputFolder)\n",
    "\n",
    "for currentClass in classes:\n",
    "    if str(currentClass) == \"test1\":\n",
    "        splitAudioInType(inputFolder, currentClass, 1, samplingRate)\n",
    "    elif str(currentClass) == \"test2\":      \n",
    "        splitAudioInType(inputFolder, currentClass, 2, samplingRate)\n",
    "    else:\n",
    "        splitAudioInType(inputFolder, currentClass, 3, samplingRate)\n",
    "\n",
    "archive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
