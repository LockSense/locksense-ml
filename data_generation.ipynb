{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-6977de27-5c92-4628-8876-2143ffa9457b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-af836cee-4371-4276-9c60-8cec935af5e6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Generative Adversarial Networks\n",
    "\n",
    "Resources:\n",
    "* https://keras.io/examples/generative/conditional_gan/\n",
    "  * See https://github.com/ipython/ipython/issues/10045 for last step (embedding gifs in notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-0d5c0522-4f22-4f2a-a57d-49476f3d9b13",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00002-00872c5a-0f3d-42b1-af29-61341c525dae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8290,
    "execution_start": 1635834959834,
    "source_hash": "dd8f1ce9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-0f86140f-1fad-4cdf-9286-c834e17af740",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Constants and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-aa36a4ec-7ba4-48eb-b616-888df475f8bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1635834968128,
    "source_hash": "3481d90a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4 # 64\n",
    "image_size = 224\n",
    "num_channels = 3\n",
    "num_classes = 3\n",
    "latent_dim = 128\n",
    "\n",
    "train_path=\"datasets/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-d9b9f1ac-5a83-4c97-992a-7c4fb823eae7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Loading & Pre-processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-024f6bd6-780c-4958-8daa-36953ad3485b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1635834969089,
    "source_hash": "303b8a99",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %run common.py\n",
    "\n",
    "def make_dataset_generator():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        brightness_range=(0.5, 1.5),\n",
    "        rotation_range=20,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator\n",
    "\n",
    "# For testing\n",
    "train_generator = make_dataset_generator()\n",
    "x_train, y_train = next(train_generator)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "def make_dataset():\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        make_dataset_generator, \n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(batch_size, image_size, image_size, num_channels)), \n",
    "            tf.TensorSpec(shape=(batch_size, num_classes))\n",
    "            )\n",
    "    )\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-d5d6ef3b-cff3-42bd-adee-0628b1c5576d",
    "deepnote_cell_type": "markdown",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1635826134074,
    "source_hash": "b8ae154d",
    "tags": []
   },
   "source": [
    "#### Calculating number of input channels for generator & discriminator\n",
    "\n",
    "i.e. the amount of noise required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00009-4bc8eff2-79c6-4d12-a62c-3708b9e627a4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1635834971067,
    "source_hash": "22b955c2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-0e54ee2f-16a9-4685-a0fa-096f1e684c72",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Creating the generator & discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00011-6d6bc09d-adcb-4b69-958e-50bec07a0046",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 290,
    "execution_start": 1635834973862,
    "source_hash": "c0892c27",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25676)             3389232   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 25676)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 14, 14, 131)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 28, 28, 128)       268416    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 56, 56, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 112, 112, 128)     262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 224, 224, 128)     262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 224, 224, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 3)       18819     \n",
      "=================================================================\n",
      "Total params: 4,463,283\n",
      "Trainable params: 4,463,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input:  (None, 131) \n",
      "\n",
      "\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      3520      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 77,505\n",
      "Trainable params: 77,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input:  (None, 224, 224, 6) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_generator():\n",
    "    generator = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((generator_in_channels,)),\n",
    "\n",
    "            # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "            # 224x224x(128 + num_classes) map.\n",
    "            layers.Dense(14 * 14 * generator_in_channels),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Reshape((14, 14, generator_in_channels)),\n",
    "\n",
    "            # Expand input to a 224x224x128 map.\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "            # Create a 224x224xnum_channels image.\n",
    "            layers.Conv2D(num_channels, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"generator\",\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "\n",
    "def make_discriminator():\n",
    "    discriminator = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((image_size, image_size, discriminator_in_channels)),\n",
    "\n",
    "            layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "            layers.GlobalMaxPooling2D(),\n",
    "            layers.Dense(1),\n",
    "        ],\n",
    "        name=\"discriminator\",\n",
    "    )\n",
    "    return discriminator\n",
    "\n",
    "\n",
    "# Check dimensions\n",
    "generator = make_generator()\n",
    "generator.summary()\n",
    "print(\"Input: \", generator.input.shape, \"\\n\\n\")\n",
    "\n",
    "discriminator=make_discriminator()\n",
    "discriminator.summary()\n",
    "print(\"Input: \", discriminator.input.shape, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-b5d04800-6f02-4e76-acc3-8c50c068591f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Creating a `ConditionalGAN` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00013-31aa03aa-c241-40ba-a59f-d6e37791b940",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1635834980193,
    "source_hash": "24b29c64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        pass\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        # TODO: confirm this isn't necessary\n",
    "        # image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Generate random labels for the generator.\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"gen_loss_tracker\": self.gen_loss_tracker.result().numpy(),\n",
    "            \"disc_loss_tracker\": self.disc_loss_tracker.result().numpy()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-c271181a-998c-4542-a18b-084ba72e2c6a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Training the Conditional GAN\n",
    "\n",
    "> I accidentally disconnected the Jupyter notebook halfway, which is why the output didn't get streamed back here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-c7ee89ca-e180-4a21-bf06-e0b84217e610",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 444,
    "execution_start": 1635834993386,
    "source_hash": "61efc62",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 images belonging to 3 classes.\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 610s 9s/step - g_loss: 0.9111 - d_loss: 0.5424\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 614s 9s/step - g_loss: 2.5801 - d_loss: 0.1052\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 609s 9s/step - g_loss: 0.7902 - d_loss: 0.9744\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 605s 9s/step - g_loss: 1.1035 - d_loss: 0.4518\n",
      "Epoch 5/20\n",
      "27/69 [==========>...................] - ETA: 6:11 - g_loss: 1.2187 - d_loss: 0.5093"
     ]
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(make_dataset_generator(), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latent_dim': 128, 'gen_loss_tracker': 1.1581442, 'disc_loss_tracker': 0.57097614}\n",
      "INFO:tensorflow:Assets written to: models/gan_1/assets\n"
     ]
    }
   ],
   "source": [
    "# %%capture output\n",
    "\n",
    "print(cond_gan.get_config())\n",
    "\n",
    "# cond_gan.save_weights(\"models/gan_1_weights/\")\n",
    "# cond_gan.discriminator.save(\"models/gan_1/discriminator/\")\n",
    "# cond_gan.generator.save(\"models/gan_1/generator/\")\n",
    "cond_gan.save(\"models/gan_1/\", save_traces=False)\n",
    "\n",
    "# output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'generator',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 131),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 25676,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.20000000298023224}},\n",
       "  {'class_name': 'Reshape',\n",
       "   'config': {'name': 'reshape',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'target_shape': (14, 14, 131)}},\n",
       "  {'class_name': 'Conv2DTranspose',\n",
       "   'config': {'name': 'conv2d_transpose',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'output_padding': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.20000000298023224}},\n",
       "  {'class_name': 'Conv2DTranspose',\n",
       "   'config': {'name': 'conv2d_transpose_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'output_padding': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.20000000298023224}},\n",
       "  {'class_name': 'Conv2DTranspose',\n",
       "   'config': {'name': 'conv2d_transpose_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'output_padding': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.20000000298023224}},\n",
       "  {'class_name': 'Conv2DTranspose',\n",
       "   'config': {'name': 'conv2d_transpose_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (4, 4),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'output_padding': None}},\n",
       "  {'class_name': 'LeakyReLU',\n",
       "   'config': {'name': 'leaky_re_lu_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'alpha': 0.20000000298023224}},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 3,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'groups': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model = tf.keras.models.load_model(\"models/gan_1\")\n",
    "\n",
    "reloaded_model.generator.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying the trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-2bb6b18e-713d-4285-a5d3-12f27a058823",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Next Steps\n",
    "\n",
    "1. Verify\n",
    "1. `ModelCheckpoint` (or some other means of saving the generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-466d271c-5dbd-4d2f-a2e0-93ebd3b5c487",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "GAN from Lecture Notes, for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-13a6f879-6017-49bb-97d5-8d12687cfbd6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "c16c9bf9",
    "tags": []
   },
   "source": [
    "```python\n",
    "num_pixels = image_size * image_size * num_channels\n",
    "\n",
    "def create_generator():\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(units = 256, input_dim = 100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    generator.add(Dense(units = 512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    generator.add(Dense(units = num_pixels, activation = 'tanh'))\n",
    "    generator.compile(loss = 'binary_crossentropy', optimizer = adam_optimizer())\n",
    "\n",
    "    return generator\n",
    "\n",
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(units = 1024, input_dim = num_pixels))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "\n",
    "    discriminator.add(Dense(units = 512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(units = 256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    discriminator.compile(loss = 'binary_crossentropy', optimizer = adam_optimizer())\n",
    "    return discriminator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-39e0a447-28d2-4b9e-812d-d82dc0a90729",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ddd5f9cd-14c1-4462-aac1-a464a84065be' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [
   {
    "cellId": "00015-c7ee89ca-e180-4a21-bf06-e0b84217e610",
    "msgId": "e0576c01-4de0-4eb4-93d6-6a51cd2c1cbf",
    "sessionId": "8217dbba-883d-49d4-9abb-ee53ddf19fa7"
   }
  ],
  "deepnote_notebook_id": "729e1823-c9b7-489a-86c1-5b236e1fe94a",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
